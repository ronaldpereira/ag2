---
sidebarTitle: LlamaIndexQueryEngine
title: autogen.agentchat.contrib.rag.LlamaIndexQueryEngine
---
<h2 id="autogen.agentchat.contrib.rag.LlamaIndexQueryEngine" class="doc doc-heading">
    <code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>
    <span class="doc doc-object-name doc-class-name">LlamaIndexQueryEngine</span>
</h2>

```python
LlamaIndexQueryEngine(
    vector_store: BasePydanticVectorStore,
    llm: ForwardRef('LLM') | None = None,
    file_reader_class: type['SimpleDirectoryReader'] | None = None
)
```

    This engine leverages LlamaIndex's VectorStoreIndex to efficiently index and retrieve documents, and generate an answer in response
    to natural language queries. It use any LlamaIndex [vector store](https://docs.llamaindex.ai/en/stable/module_guides/storing/vector_stores/).<br/>By default the engine will use OpenAI's GPT-4o model (use the `llm` parameter to change that).<br/>Initializes the LlamaIndexQueryEngine with the given vector store.<br/>

<b>Parameters:</b>
| Name | Description |
|--|--|
| `vector_store` | **Type:** BasePydanticVectorStore |
| `llm` | **Type:** ForwardRef('LLM') \| None<br/><br/>**Default:** None |
| `file_reader_class` | **Type:** type['SimpleDirectoryReader'] \| None<br/><br/>**Default:** None |

### Instance Methods

<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>
#### add_docs

```python
add_docs(
    self,
    new_doc_dir: Path | str | None = None,
    new_doc_paths_or_urls: Sequence[Path | str] | None = None,
    *args: Any,
    **kwargs: Any
) -> None
```

    Add new documents to the underlying database and add to the index.<br/>

<b>Parameters:</b>
| Name | Description |
|--|--|
| `new_doc_dir` | A dir of input documents that are used to create the records in database.<br/><br/>**Type:** pathlib.Path \| str \| None<br/><br/>**Default:** None |
| `new_doc_paths_or_urls` | A sequence of input documents that are used to create the records in database.<br/><br/>A document can be a Path to a file or a url.<br/><br/>**Type:** Sequence[pathlib.Path \| str] \| None<br/><br/>**Default:** None |
| `*args` | Any additional arguments<br/><br/>**Type:** Any |
| `**kwargs` | Any additional keyword arguments<br/><br/>**Type:** Any |

<br />

<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>
#### connect_db

```python
connect_db(
    self,
    *args: Any,
    **kwargs: Any
) -> bool
```

    Connect to the database.<br/>It sets up the LlamaIndex storage and create an index from the existing vector store.<br/>

<b>Parameters:</b>
| Name | Description |
|--|--|
| `*args` | Any additional arguments<br/><br/>**Type:** Any |
| `**kwargs` | Any additional keyword arguments<br/><br/>**Type:** Any |

<b>Returns:</b>
| Type | Description |
|--|--|
| bool | bool: True if connection is successful |

<br />

<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>
#### init_db

```python
init_db(
    self,
    new_doc_dir: Path | str | None = None,
    new_doc_paths_or_urls: Sequence[Path | str] | None = None,
    *args: Any,
    **kwargs: Any
) -> bool
```

    Initialize the database with the input documents or records.<br/>It takes the following steps: <br/>1. Set up LlamaIndex storage context.<br/>2. insert documents and build an index upon them.<br/>

<b>Parameters:</b>
| Name | Description |
|--|--|
| `new_doc_dir` | a dir of input documents that are used to create the records in database.<br/><br/>**Type:** pathlib.Path \| str \| None<br/><br/>**Default:** None |
| `new_doc_paths_or_urls` | A sequence of input documents that are used to create the records in database.<br/><br/>A document can be a Path to a file or a url.<br/><br/>**Type:** Sequence[pathlib.Path \| str] \| None<br/><br/>**Default:** None |
| `*args` | Any additional arguments<br/><br/>**Type:** Any |
| `**kwargs` | Any additional keyword arguments<br/><br/>**Type:** Any |

<b>Returns:</b>
| Type | Description |
|--|--|
| bool | bool: True if initialization is successful |

<br />

<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>
#### query

```python
query(self, question: str) -> str
```

    Retrieve information from indexed documents by processing a query using the engine's LLM.<br/>

<b>Parameters:</b>
| Name | Description |
|--|--|
| `question` | A natural language query string used to search the indexed documents.<br/><br/>**Type:** str |

<b>Returns:</b>
| Type | Description |
|--|--|
| str | A string containing the response generated by LLM. |

<br />